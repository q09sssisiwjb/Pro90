import { GoogleGenAI, Modality } from "@google/genai";

// DON'T DELETE THIS COMMENT
// Using Gemini integration - modified for gemini-2.0-flash-exp as requested by user

// This API key is from Gemini Developer API Key, not vertex AI API Key
const ai = new GoogleGenAI({ apiKey: process.env.GOOGLE_API_KEY || process.env.GEMINI_API_KEY || "" });

export async function generateTextToImage(
    prompt: string,
): Promise<{ imageData: string; description?: string }> {
    try {
        const response = await ai.models.generateContent({
            model: "gemini-2.0-flash-exp",
            contents: [
                {
                    role: "user",
                    parts: [{ text: `Generate an image: ${prompt}` }],
                },
            ],
            config: {
                responseModalities: [Modality.TEXT, Modality.IMAGE],
            },
        });

        const candidates = response.candidates;
        if (!candidates || candidates.length === 0) {
            throw new Error("No candidates returned from Gemini");
        }

        const content = candidates[0].content;
        if (!content || !content.parts) {
            throw new Error("No content parts returned from Gemini");
        }

        let generatedImageData: string | undefined;
        let description: string | undefined;

        for (const part of content.parts) {
            if (part.text) {
                description = part.text;
                console.log("Generated description:", part.text);
            } else if (part.inlineData && part.inlineData.data) {
                generatedImageData = part.inlineData.data;
                console.log("Generated image data received");
            }
        }

        if (!generatedImageData) {
            throw new Error("No image data generated by Gemini");
        }

        return {
            imageData: generatedImageData,
            description,
        };
    } catch (error) {
        throw new Error(`Failed to generate text-to-image: ${error instanceof Error ? error.message : String(error)}`);
    }
}

export async function generateImageToImage(
    images: { data: string; type: string }[],
    transformPrompt: string,
): Promise<{ imageData: string; description?: string }> {
    try {
        // Build parts array with all images and the transformation prompt
        const parts: any[] = [];
        
        // Add all images to the parts array
        images.forEach((image, index) => {
            parts.push({
                inlineData: {
                    data: image.data,
                    mimeType: image.type,
                },
            });
        });

        // Add the transformation prompt
        const promptText = images.length === 1 
            ? `Transform this image: ${transformPrompt}. Generate a new image based on this transformation.`
            : `Combine and transform these ${images.length} images: ${transformPrompt}. Create a new image that incorporates elements from all the provided images according to the transformation.`;
        
        parts.push({
            text: promptText,
        });

        // Use gemini-2.0-flash-exp as specifically requested
        const response = await ai.models.generateContent({
            model: "gemini-2.0-flash-exp",
            contents: [
                {
                    role: "user",
                    parts: parts,
                },
            ],
            config: {
                responseModalities: [Modality.TEXT, Modality.IMAGE],
            },
        });

        const candidates = response.candidates;
        if (!candidates || candidates.length === 0) {
            throw new Error("No candidates returned from Gemini");
        }

        const content = candidates[0].content;
        if (!content || !content.parts) {
            throw new Error("No content parts returned from Gemini");
        }

        let generatedImageData: string | undefined;
        let description: string | undefined;

        for (const part of content.parts) {
            if (part.text) {
                description = part.text;
                console.log("Generated description:", part.text);
            } else if (part.inlineData && part.inlineData.data) {
                generatedImageData = part.inlineData.data;
                console.log("Generated image data received");
            }
        }

        if (!generatedImageData) {
            throw new Error("No image data generated by Gemini");
        }

        return {
            imageData: generatedImageData,
            description,
        };
    } catch (error) {
        throw new Error(`Failed to generate image-to-image: ${error instanceof Error ? error.message : String(error)}`);
    }
}